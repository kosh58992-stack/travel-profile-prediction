# **Сопроводительный документ о проведенной работе по проекту**
## **Прогнозирование смены travel-профиля клиентов на основе динамики доходов и транзакционных признаков**

Студент: Кошмелева Марина Олеговна
Курс: ДПО "Аналитик данных", ВШЭ, 2026
Руководитель: Паточенко Евгений Анатольевич

---

## **1. Постановка задачи**

**Бизнес-задача:**
Компания, обладающая программой лояльности для клиентов travel-сегмента, стремится увеличить пожизненную ценность (LTV) клиентов за счет своевременного предложения перехода на более высокий уровень программы. В настоящий момент маркетинговые коммуникации осуществляются массово, что приводит к неэффективному расходованию бюджета и низкой конверсии (только 2.88% клиентов реально повышают уровень).

**Цель проекта:**
Разработать модель машинного обучения, которая прогнозирует клиентов, с высокой вероятностью готовых повысить свой уровень в программе лояльности, на основе анализа их транзакционной истории, демографических данных и поведенческих паттернов.

**Ожидаемый результат:**
- Модель с качеством ROC-AUC не менее 0.75
- Ранжированный список факторов, влияющих на смену профиля
- Конкретные бизнес-рекомендации для департамента маркетинга
- Оценка экономического эффекта от внедрения модели

**Ценность для бизнеса:**
- Увеличение LTV клиентов на 15-20%
- Снижение стоимости привлечения (CPA) на 25%
- Повышение удержания ценных клиентов на 10-15%

---

## **2. Описание этапов работы и выводы**

### **Этап 1: Загрузка и первичный анализ данных**

**Что сделано:**
Я загрузила датасет `dano_dataset_travel.csv` объемом 835 938 записей и 56 признаков. Провела первичный анализ структуры данных, типов колонок и количества пропусков. Для этого использовала стандартные библиотеки Pandas и NumPy, методы `info()`, `describe()`, `isnull().sum()`.

**Почему выбраны такие методы:**
Метод `info()` позволил быстро оценить типы данных и наличие пропусков, а `describe()` — понять распределение числовых признаков. Это стандартный подход для первичного знакомства с данными.

**Как устроен процесс:**
1. Загрузка данных через `pd.read_csv()`
2. Проверка размерности (`shape`)
3. Анализ типов данных и пропусков (`info()`, `isnull().sum()`)
4. Проверка уникальных значений по ключевым полям (`nunique()`)

**Выводы по этапу:**
Датасет содержит 56 колонок с информацией о клиентах и их транзакциях. Выявлены проблемы с качеством данных: 12 колонок имеют критический уровень пропусков (>50%), 52 колонки имеют тип object и требуют конвертации. Это значит, что предстоит большая работа по очистке и подготовке данных.

---

### **Этап 2: Предобработка данных и работа с пропусками**

**Что сделано:**
Я провела масштабную предобработку данных: удалила колонки с критическим уровнем пропусков (>50%), обработала пропуски в категориальных и числовых признаках, преобразовала форматы данных.

**Почему выбраны такие методы:**
- Колонки с пропусками >50% (12 штук) я удалила, потому что такие данные не несут полезной информации и могут исказить результаты
- Категориальные признаки заполнила значением 'UNKNOWN' и создала флаги пропусков — это позволяет сохранить информацию о самом факте пропуска
- Числовые признаки заполнила медианой, так как она устойчива к выбросам
- Для колонок с датами применила преобразование в формат datetime

**Как устроен процесс:**
1. Удаление колонок с пропусками >50%
2. Преобразование дат в формат datetime
3. Конвертация числовых признаков из строкового формата (замена запятых на точки)
4. Заполнение пропусков в категориальных признаках ('UNKNOWN')
5. Заполнение числовых пропусков медианой
6. Создание флагов пропусков

**Выводы по этапу:**
После обработки удалось сохранить 45 колонок из 56. Все пропуски в данных обработаны, типы данных приведены к корректному формату. Особое внимание уделила колонкам с датами — их правильная обработка критична для дальнейшего анализа временных рядов.

---

### **Этап 3: Генерация признаков (Feature Engineering)**

**Что сделано:**
Я создала более 40 новых признаков на основе исходных данных, включая агрегированные показатели по клиентам, временные характеристики и поведенческие паттерны. Для этого написала несколько функций: `create_income_features`, `create_spending_features`, `create_time_features` и другие.

**Почему выбраны такие методы:**
- Агрегация по клиентам необходима, потому что целевая переменная определяется на уровне клиента, а не транзакции
- Признаки дохода с временной динамикой важны для оценки платежеспособности
- Метрики по стоимости заказов (средний чек, стандартное отклонение) характеризуют потребительское поведение
- Временные признаки (lifetime, давность последней активности) критичны для прогнозирования изменений

**Как устроен процесс:**
1. Создание признаков дохода (среднее, минимум, максимум, последнее значение)
2. Расчет метрик по тратам (сумма, средний чек, количество заказов)
3. Определение любимого типа заказа (HOT/AIR)
4. Расчет разнообразия заказов
5. Создание временных признаков (lifetime, дни с первого заказа)
6. Анализ отмен заказов
7. Объединение всех признаков в единый датасет

**Выводы по этапу:**
Сформирован датасет размером 148 361 клиент × 45 признаков. Самым важным открытием стало то, что данные по первой и последней активности клиента охватывают период с 2017 по 2024 год, что дает достаточно времени для наблюдения изменений в уровне лояльности.

---

### **Этап 4: Исследовательский анализ данных (EDA)**

**Что сделано:**
Я провела детальный анализ распределений, корреляций и взаимосвязей между признаками. Визуализировала ключевые зависимости с помощью гистограмм, корреляционных матриц и boxplot'ов.

**Почему выбраны такие методы:**
Гистограммы помогают понять распределение признаков, корреляционные матрицы — выявить взаимосвязи, а boxplot'ы — обнаружить выбросы. Это стандартный набор инструментов для разведочного анализа.

**Как устроен процесс:**
1. Анализ распределения возраста, дохода, сумм трат
2. Исследование программ лояльности и создание иерархии уровней (от 1 до 5)
3. Корреляционный анализ числовых признаков
4. Анализ выбросов по каждой числовой колонке
5. Визуализация ключевых зависимостей

**Выводы по этапу:**
Выявлен сильный дисбаланс классов — только 2.88% клиентов реально повысили уровень лояльности. Определены ключевые факторы, влияющие на повышение: бонусные начисления, "возраст" клиента, финансовые показатели. Обнаружены выбросы в ряде признаков (до 29% в avg_bonus), что потребовало дополнительной обработки.

---

### **Этап 5: Создание целевой переменной**

**Что сделано:**
Я создала целевую переменную `target_upgrade`, которая отражает факт повышения уровня лояльности клиента за всю историю наблюдений. Для этого использовала агрегацию по клиентам с сравнением первого и последнего уровня лояльности.

**Почему выбран такой подход:**
Этот подход позволяет максимально полно использовать временной диапазон данных (2017-2024 гг.) и дает больше времени для наблюдения изменений, чем использование фиксированной даты cutoff.

**Как устроен процесс:**
1. Агрегация данных по каждому клиенту
2. Определение первого и последнего уровня лояльности
3. Создание бинарной переменной (1 — уровень повышен, 0 — не повышен)
4. Объединение с созданными признаками

**Выводы по этапу:**
Получено 856 положительных примеров (повышение уровня) из 29 673 клиентов в тестовой выборке. Это подтверждает сильный дисбаланс классов, который нужно будет учитывать при обучении моделей.

---

### **Этап 6: Обработка пропусков в финальном датасете**

**Что сделано:**
Я обработала оставшиеся пропуски в категориальных и числовых признаках финального датасета.

**Почему выбраны такие методы:**
- Категориальные признаки (`marital_status_cd`, `education_level_cd`) заполнила 'UNKNOWN' и создала флаги пропусков
- Числовой признак `customer_lifetime_days` заполнила нулями для клиентов без первого заказа (это логично — у них нет истории)

**Как устроен процесс:**
1. Заполнение `marital_status_cd` и `education_level_cd` значением 'UNKNOWN'
2. Создание флагов пропусков
3. Заполнение `customer_lifetime_days` нулями для клиентов без первого заказа

**Выводы по этапу:**
Все пропуски успешно обработаны. Интересно, что клиенты без первого заказа (около 49 тыс.) никогда не повышают уровень лояльности — это важный инсайт для модели.

---

### **Этап 7: Анализ и обработка выбросов**

**Что сделано:**
Я провела анализ выбросов в числовых признаках и применила логарифмические преобразования для сильно скошенных распределений.

**Почему выбраны такие методы:**
- Логарифмирование для `total_spent`, `avg_bonus`, `avg_order_value` позволяет нормализовать распределение и снизить влияние выбросов
- Создание флагов для экстремальных значений сохраняет информацию о "VIP-клиентах"
- Исходные колонки сохранены для возможности сравнения

**Как устроен процесс:**
1. Расчет статистики по выбросам для каждой колонки
2. Логарифмическое преобразование для сильно скошенных признаков
3. Создание флагов для экстремальных значений (`is_vip_spender`, `is_high_bonus`, `is_high_income`)
4. Сохранение обработанного датасета

**Выводы по этапу:**
Наибольший процент выбросов оказался в признаках, связанных с бонусами (avg_bonus — 29%). Это логично, так есть клиенты, которые очень активно пользуются бонусной программой. Таких клиентов не стоит удалять — это потенциально самые ценные клиенты.

---

### **Этап 8: Обучение и сравнение моделей**

**Что сделано:**
Я обучила и сравнила три модели машинного обучения: Logistic Regression, Random Forest и XGBoost. Провела оценку качества с использованием различных метрик с учетом дисбаланса классов.

**Почему выбраны такие методы:**
- Logistic Regression — базовая интерпретируемая модель для сравнения
- Random Forest — устойчив к выбросам, хорошо работает с нелинейными зависимостями
- XGBoost — современный градиентный бустинг, показывает лучшие результаты на структурированных данных
- Метрики: ROC-AUC, PR-AUC, Precision, Recall, F1-Score — позволяют комплексно оценить модель с учетом дисбаланса классов

**Как устроен процесс:**
1. Разделение данных на train/test (80/20) со стратификацией
2. Создание пайплайнов предобработки для каждой модели
3. Обучение моделей с регуляризацией и балансировкой классов
4. Расчет всех метрик
5. Сравнение результатов и выбор лучшей модели

**Результаты моделей:**

| Модель | ROC-AUC | PR-AUC | Recall | F1-Score | TP | FN | FP | TN |
|--------|---------|--------|--------|----------|----|----|----|-----|
| Logistic Regression | 0.7577 | 0.0673 | 85.5% | 0.0985 | 732 | 124 | 13272 | 15545 |
| Random Forest | 0.8015 | 0.0875 | 87.0% | 0.1106 | 745 | 111 | 11868 | 16949 |
| XGBoost | 0.8184 | 0.0990 | 80.4% | 0.1277 | 688 | 168 | 9235 | 19582 |

**Выводы по этапу:**
XGBoost показал лучший результат по ROC-AUC (0.8184) и F1-Score (0.1277), а также минимальное количество ложных срабатываний (9 235). Random Forest лучше справляется с поиском повышений (Recall 87%), но дает больше ложных срабатываний. Logistic Regression показала достойный базовый уровень (ROC-AUC 0.7577). Для бизнеса я рекомендую XGBoost как наиболее сбалансированную модель.

---

### **Этап 9: Расчет экономического эффекта**

**Что сделано:**
На основе метрик лучшей модели (XGBoost) я рассчитала потенциальный экономический эффект от внедрения.

**Почему выбраны такие методы:**
Использовала стандартные бизнес-метрики: средний LTV клиента (50 000 руб), прирост LTV при повышении уровня (25%), стоимость маркетинговой кампании на одного клиента (1 000 руб), стоимость внедрения модели (500 000 руб).

**Как устроен процесс:**
1. Расчет дохода от правильно предсказанных повышений
2. Оценка потерянного потенциала от пропущенных случаев
3. Расчет экономии маркетингового бюджета за счет снижения ложных срабатываний
4. Вычисление ROI и прогноз на всю клиентскую базу (148 361 клиент)

**Результаты расчета:**
- Дополнительный доход на тестовой выборке: 8 600 000 руб
- Экономия маркетингового бюджета: 9 235 000 руб
- Чистый эффект на тестовой выборке: 16 835 000 руб
- ROI: 3367%
- Прогноз на всю клиентскую базу: дополнительный доход 44 400 000 руб/год

**Выводы по этапу:**
Модель показывает впечатляющую экономическую эффективность. ROI 3367% означает, что каждый вложенный рубль приносит почти 34 рубля прибыли. Основной вклад дает экономия маркетингового бюджета за счет отсутствия ложных срабатываний.

---

## **3. Общие выводы и рекомендации**

### **Как полученные результаты помогают в принятии решений**

1. **Для маркетинга:**
   - Модель позволяет выделить сегмент из ~15 000 наиболее перспективных клиентов
   - Маркетинговый бюджет можно перераспределить с массовых рассылок на точечные коммуникации
   - Ожидаемая экономия бюджета составляет более 9 млн руб на тестовой выборке

2. **Для продукта:**
   - Выявлены ключевые факторы повышения уровня: бонусные начисления, "возраст" клиента, финансовые показатели
   - Это понимание можно использовать для разработки более эффективных программ лояльности
   - Клиенты, активно получающие бонусы, с наибольшей вероятностью готовы к переходу на следующий уровень

3. **Для стратегии:**
   - Подтверждена целесообразность внедрения ML-моделей для оптимизации маркетинга
   - ROI 3367% говорит о высокой эффективности инвестиций в анализ данных
   - Модель может быть масштабирована на другие сегменты и продукты

### **Рекомендации для бизнеса**

1. **Внедрить скоринговую систему в CRM**
   - Автоматический расчет вероятности повышения для каждого клиента
   - Формирование динамического сегмента "Потенциальные повышатели"
   - Ожидаемый дополнительный доход: 44.4 млн руб/год

2. **Запустить таргетированную программу лояльности**
   - Сегмент "Потенциальные повышатели" ≈ 15 000 клиентов с highest probability
   - Персонализированные предложения с ускоренным накоплением бонусов
   - Ожидаемый рост конверсии: +15-20%

3. **Оптимизировать маркетинговый бюджет**
   - Сократить массовые рассылки на 30%
   - Перенаправить бюджет на таргетированные кампании
   - Экономия маркетингового бюджета: 9.2 млн руб на тестовой выборке

4. **Создать систему раннего оповещения**
   - Для клиентов с вероятностью >70% запускать предапрув за 1-2 месяца
   - Автоматические триггерные коммуникации (email/SMS)
   - Сокращение времени повышения на 30%

5. **Дообучать модель ежеквартально**
   - Мониторинг качества предсказаний в реальном времени
   - Добавление новых поведенческих признаков
   - Цель: достичь ROC-AUC = 0.85

### **Возможные ограничения исследования**

1. **Дисбаланс классов** (2.88% положительных примеров) ограничивает точность модели. Precision составляет всего 6.9%, что означает много ложных срабатываний.

2. **Ограниченный временной период** данных — большинство транзакций приходятся на 2024 год, что может не отражать долгосрочные паттерны поведения.

3. **Отсутствие внешних данных** — в модели не учитываются макроэкономические факторы, сезонность, маркетинговые активности конкурентов.

4. **Технические ограничения** — модель требует калибровки при изменении продуктовой линейки или условий программы лояльности.

5. **Бизнес-ограничения** — для внедрения потребуется интеграция с CRM и обучение персонала работе с новым инструментом.

### **Следующие шаги**

1. Пилотное внедрение на контрольной группе (5-10% клиентов)
2. A/B тестирование для валидации экономических показателей
3. Сбор обратной связи и дообучение модели через 3 месяца
4. Масштабирование на всю клиентскую базу при подтверждении эффективности
5. Разработка аналогичных моделей для других продуктовых сегментов

---

*Разработчик: Кошмелева Марина Олеговна*
*Курс: ДПО "Аналитик данных", ВШЭ, 2026*
*Руководитель: Паточенко Евгений Анатольевич*

